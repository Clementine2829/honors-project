{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e514866d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import math\n",
    "\n",
    "from network import Network\n",
    "from fc_layer import FCLayer\n",
    "from activation_layer import ActivationLayer\n",
    "from activations import tanh, tanh_prime, mse, mse_prime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "83fb1e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kdd_train_pre_processing(df):\n",
    "\n",
    "    \"\"\" partioning data into features and target \"\"\"\n",
    "    df[['class']] = np.where(df[['class']] == 'normal', 1, 0)\n",
    "    df.loc[df[\"protocol_type\"] == \"tcp\", \"protocol_type\"] = 1\n",
    "    df.loc[df[\"protocol_type\"] == \"udp\", \"protocol_type\"] = 2\n",
    "    df.loc[df[\"protocol_type\"] == \"icmp\", \"protocol_type\"] = 3\n",
    "    \n",
    "    \n",
    "    X = df[['duration','protocol_type','src_bytes','dst_bytes']]\n",
    "    y = df[df.columns[-1]]\n",
    "    \n",
    "#    print(\"Pre processing x\")\n",
    "#    print(X)\n",
    "\n",
    "#    print(\"Pre processing y\")\n",
    "#    print(y)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def kdd_test_pre_processing(df):\n",
    "\n",
    "    \"\"\" partioning data into features and target \"\"\"\n",
    "    df.loc[df[\"protocol_type\"] == \"tcp\", \"protocol_type\"] = 1\n",
    "    df.loc[df[\"protocol_type\"] == \"udp\", \"protocol_type\"] = 2\n",
    "    df.loc[df[\"protocol_type\"] == \"icmp\", \"protocol_type\"] = 3\n",
    "    \n",
    "    \n",
    "    X = df[['duration','protocol_type','src_bytes','dst_bytes']]\n",
    "    y = df.add(\"class\", axis=1)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6477c4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_data(x, y, test_size = 0.25, random_state = None):\n",
    "    \"\"\" partioning the data into train and test sets \"\"\"\n",
    "\n",
    "    x_test = x.sample(frac=test_size, random_state=random_state)\n",
    "    y_test = y[x_test.index]\n",
    "\n",
    "    x_train = x.drop(x_test.index)\n",
    "    y_train = y.drop(y_test.index)\n",
    "\n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "def test_data(x, y, test_size = 0.25, random_state = None):\n",
    "    \"\"\" partioning the data into train and test sets \"\"\"\n",
    "\n",
    "    x = x.sample(frac = test_size, random_state = random_state)\n",
    "    \n",
    "    return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8e75c875",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_test(x):\n",
    "    x.float()\n",
    "    return np.exp(x)\n",
    "\n",
    "def to_float_fun(x):\n",
    "    for i in range(len(x)):\n",
    "        #[i]= x[i].astype(np.float)\n",
    "        for j in range(len(x[i])):\n",
    "                x[i][j] = str(x[i][j]) + \".\"\n",
    "                x[i][j] = round(float(x[i][j]), 0)\n",
    "                #x[i][j] = math.floor(x[i][j])\n",
    "                #x[i][j] = x[i][j].astype(np.float)\n",
    "\n",
    "    return x\n",
    "\n",
    "def to_float_cut(x):\n",
    "    return math.floor(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4208d094",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_data(x):\n",
    "    arr = []\n",
    "    print(len(x))\n",
    "    for i in range(x.size):\n",
    "        temp_arr = []\n",
    "        temp_arr.append(arr[i])\n",
    "        arr.append(temp_arr)\n",
    "\n",
    "    return arr\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a6ce007e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np_utils' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\CLEMEN~1\\AppData\\Local\\Temp/ipykernel_8384/2894245513.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[0mX_train\u001b[0m \u001b[1;33m/=\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np_utils' is not defined"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"./data/train_data.csv\")\n",
    "df_test = pd.read_csv(\"./data/test_data.csv\")\n",
    "\n",
    "\n",
    "#print(df)\n",
    "#print(df.columns)\n",
    "#print(len(df.columns))\n",
    "\n",
    "# Split fearures and target\n",
    "X_train, y_train = kdd_train_pre_processing(df_train)\n",
    "#X_test, y_test = kdd_test_pre_processing(df_test)\n",
    "\n",
    "\n",
    "# Split data into Training and Testing Sets\n",
    "X_train, X_test, y_train, y_test = train_data(X_train, y_train, test_size=.8, random_state=0)\n",
    "#X_test, y_test = test_data(X_test, y_test, test_size=1, random_state=0)\n",
    "\n",
    "# remove labels and convert to array\n",
    "X_train = X_train.to_numpy()\n",
    "y_train = y_train.to_numpy()\n",
    "X_test = X_test.to_numpy()\n",
    "y_test = y_test.to_numpy()\n",
    "\n",
    "#.T -> change the matrix\n",
    "#X_train, y_train, X_test, y_test = X_train.T, y_train.T, X_test.T, y_test.T\n",
    "#y_train = y_train.reshape(1, -1)\n",
    "#y_test = y_test.reshape(1, -1)\n",
    "\n",
    "#print(X_train)\n",
    "X_train = X_train.reshape(-1, 1, 4)\n",
    "X_train = X_train.astype('float32')\n",
    "X_train /= 255\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "\n",
    "X_test = X_test.reshape(-1, 1, 4)\n",
    "X_test = X_test.astype('float32')\n",
    "X_test /= 255\n",
    "\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "\n",
    "\n",
    "print(X_train)\n",
    "print(\"\\n\")\n",
    "print(y_train)\n",
    "print(\"\\n\")\n",
    "print(X_test)\n",
    "print(\"\\n\")\n",
    "print(y_test)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a192fa8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/35   error=0.113934\n",
      "epoch 2/35   error=0.091867\n",
      "epoch 3/35   error=0.088354\n",
      "epoch 4/35   error=0.085359\n",
      "epoch 5/35   error=0.084125\n",
      "epoch 6/35   error=0.080902\n",
      "epoch 7/35   error=0.079723\n",
      "epoch 8/35   error=0.079242\n",
      "epoch 9/35   error=0.078854\n",
      "epoch 10/35   error=0.078414\n",
      "epoch 11/35   error=0.078096\n",
      "epoch 12/35   error=0.078199\n",
      "epoch 13/35   error=0.079433\n",
      "epoch 14/35   error=0.078773\n",
      "epoch 15/35   error=0.077934\n",
      "epoch 16/35   error=0.082616\n",
      "epoch 17/35   error=0.081282\n",
      "epoch 18/35   error=0.079883\n",
      "epoch 19/35   error=0.078472\n",
      "epoch 20/35   error=0.076871\n",
      "epoch 21/35   error=0.083464\n",
      "epoch 22/35   error=0.083860\n",
      "epoch 23/35   error=0.083558\n",
      "epoch 24/35   error=0.083321\n",
      "epoch 25/35   error=0.083035\n",
      "epoch 26/35   error=0.082519\n",
      "epoch 27/35   error=0.080998\n",
      "epoch 28/35   error=0.079019\n",
      "epoch 29/35   error=0.078781\n",
      "epoch 30/35   error=0.078744\n",
      "epoch 31/35   error=0.078728\n",
      "epoch 32/35   error=0.078718\n",
      "epoch 33/35   error=0.078708\n",
      "epoch 34/35   error=0.078694\n",
      "epoch 35/35   error=0.078677\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "loop of ufunc does not support argument 0 of type float which has no callable tanh method",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: 'float' object has no attribute 'tanh'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\CLEMEN~1\\AppData\\Local\\Temp/ipykernel_8384/3335047010.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m# test on 3 samples\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"predicted values : \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\pythonProject\\NeuralNetworkClass\\network.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, input_data)\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m                 \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_propagation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m             \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\pythonProject\\NeuralNetworkClass\\activation_layer.py\u001b[0m in \u001b[0;36mforward_propagation\u001b[1;34m(self, input_data)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward_propagation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\pythonProject\\NeuralNetworkClass\\activations.py\u001b[0m in \u001b[0;36mtanh\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# activation function and its derivative\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtanh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtanh_prime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: loop of ufunc does not support argument 0 of type float which has no callable tanh method"
     ]
    }
   ],
   "source": [
    "# Network\n",
    "net = Network()\n",
    "net.add(FCLayer(4, 12))                # input_shape=(1, 28*28)    ;   output_shape=(1, 100)\n",
    "net.add(ActivationLayer(tanh, tanh_prime))\n",
    "net.add(FCLayer(12, 8))                   # input_shape=(1, 100)      ;   output_shape=(1, 50)\n",
    "net.add(ActivationLayer(tanh, tanh_prime))\n",
    "net.add(FCLayer(8, 2))                    # input_shape=(1, 50)       ;   output_shape=(1, 10)\n",
    "net.add(ActivationLayer(tanh, tanh_prime))\n",
    "\n",
    "# train on 1000 samples\n",
    "# as we didn't implemented mini-batch GD, training will be pretty slow if we update at each iteration on 60000 samples...\n",
    "net.use(mse, mse_prime)\n",
    "net.fit(X_train[0:1000], y_train[0:1000], epochs=35, learning_rate=0.1)\n",
    "\n",
    "# test on 3 samples\n",
    "out = net.predict(X_test[0:])\n",
    "print(\"\\n\")\n",
    "print(\"predicted values : \")\n",
    "print(out, end=\"\\n\")\n",
    "print(\"true values : \")\n",
    "print(y_test[0:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bd380b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
